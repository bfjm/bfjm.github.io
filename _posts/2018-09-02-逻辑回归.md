---
layout: post
title: 逻辑回归
date: 2018-09-02 11:00 +0800
categories: ml
tags: 逻辑回归
---
逻辑回归又称对数几率回归，一般用在分类问题  
  
```python
import numpy as np
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```
这样构建的Cost(hθ (x), y)函数的特点是:当实际的 y = 1 且hθ (x)也为 1 时误差为 0,  
当 y = 1 但hθ (x)不为 1 时误差随着hθ (x)变小而变大;当实际的 y = 0 且hθ (x)也为 0 时  
代价为 0,当y = 0 但hθ (x)不为 0 时误差随着 hθ (x)的变大而变大。

代价函数
```python
import numpy as np
def cost(theta, X, y):
    theta = np.matrix(theta)
    X = np.matrix(X)
    y = np.matrix(y)
    first = np.multiply(-y, np.log(sigmoid(X* theta.T)))
    second = np.multiply((1 - y), np.log(1 - sigmoid(X* theta.T)))
    return np.sum(first - second) / (len(X))
```